// Copyright (c) 2025 Huawei Technologies Co., Ltd.
// This program is free software, you can redistribute it and/or modify it under the terms and conditions of
// CANN Open Software License Agreement Version 2.0 (the "License").
// Please refer to the License for details. You may not use this file except in compliance with the License.
// THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
// INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
// See LICENSE in the root of the software repository for the full text of the License.

// RUN: ascir-translate -mlir-to-ascendc %s | FileCheck %s

// CHECK-LABEL:void emit_kfc_server(AscendC::KfcServer v1, __gm__ int8_t* v2, AscendC::TPipe v3, constexpr static MatmulConfig CFG{1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,BatchMode::NONE,1,1,1,1,1,1,1,255,1,0,0,0,IterateOrder::UNDEF,ScheduleType::INNER_PRODUCT,0,1,0,0,0,0,0,0,0,65536,BatchOutMode::SINGLE_BATCH};matmul::Matmul<matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, float, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, float, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, float, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, float>, CFG> v4) {
// CHECK-NEXT:  v1.Init(v2);
// CHECK-NEXT:  v1.InitObj(&v3, v4);
// CHECK-NEXT:  int8_t v5 = v1.isRun();
// CHECK-NEXT:  v1.Run(v4);
// CHECK-NEXT:  v1.Quit();
// CHECK-NEXT:  return;
// CHECK-NEXT:}
func.func @emit_kfc_server(%arg0: !ascendc.kfc_server, %arg1: memref<?xi8, 22>, %arg2: !ascendc.pipe, %arg3: !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>) {
  ascendc.kfc_server.init %arg0, %arg1 : !ascendc.kfc_server, memref<?xi8, 22>
  ascendc.kfc_server.init_obj %arg0, %arg2, %arg3 : !ascendc.kfc_server, !ascendc.pipe, !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>
  %0 = ascendc.kfc_server.is_run %arg0 : i8
  ascendc.kfc_server.run %arg0, %arg3 : !ascendc.kfc_server, !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>
  ascendc.kfc_server.quit %arg0 : !ascendc.kfc_server
  return
}

// CHECK-LABEL:void emit_matmul(constexpr static MatmulConfig CFG{1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,BatchMode::NONE,1,1,1,1,1,1,1,255,1,0,0,0,IterateOrder::UNDEF,ScheduleType::INNER_PRODUCT,0,1,0,0,0,0,0,0,0,65536,BatchOutMode::SINGLE_BATCH};matmul::Matmul<matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, float, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, float, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, float, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, float>, CFG> v1, TCubeTiling v2, AscendC::TPipe v3, AscendC::GlobalTensor<float> v4, int8_t v5, AscendC::LocalTensor<float> v6, int32_t v7, uint32_t v8, __gm__ uint8_t* v9, uint8_t v10) {
// CHECK-NEXT:  constexpr int8_t c0_i8 = 0;
// CHECK-NEXT:  constexpr bool c0_i1 = false;
// CHECK-NEXT:  constexpr bool cm1_i1 = true;
// CHECK-NEXT:  v1.Init(&v2);
// CHECK-NEXT:  v1.SetTensorA(v4, v5);
// CHECK-NEXT:  v1.SetTensorB(v4, v5);
// CHECK-NEXT:  v1.SetHF32(c0_i1, v7);
// CHECK-NEXT:  v1.SetTail(v7, v7, v7);
// CHECK-NEXT:  v1.SetBatchNum(v7, v7);
// CHECK-NEXT:  v1.SetWorkspace(v4);
// CHECK-NEXT:  v1.SetWorkspace(v9, v7)
// CHECK-NEXT:  v1.WaitGetTensorC();
// CHECK-NEXT:  v1.AsyncGetTensorC(v6);
// CHECK-NEXT:  v1.IterateNBatch<c0_i1, c0_i1>(v7, v7, v7, c0_i1, v7, v7, v7);
// CHECK-NEXT:  v1.SetBias(v4);
// CHECK-NEXT:  v1.DisableBias();
// CHECK-NEXT:  bool v11 = v1.Iterate<cm1_i1>(c0_i1);
// CHECK-NEXT:  v1.GetTensorC<cm1_i1>(v6, c0_i8, cm1_i1);
// CHECK-NEXT:  v1.IterateAll<c0_i1>(v4, v5, c0_i1, cm1_i1, c0_i1);
// CHECK-NEXT:  v1.WaitIterateAll();
// CHECK-NEXT:  v1.IterateBatch<c0_i1, cm1_i1>(v4, v8, v8, c0_i1, v8, v8, v8, c0_i1, v5);
// CHECK-NEXT:  v1.WaitIterateBatch();
// CHECK-NEXT:  MatmulConfig v12;
// CHECK-NEXT:  v12.doNorm = c0_i1;
// CHECK-NEXT:  v12.iterateMode = v10;
// CHECK-NEXT:  v12.singleCoreMN = v8;
// CHECK-NEXT:  MatmulApiStaticTiling v13 = GetMatmulApiTiling<matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, float, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, float, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::VECCALC, CubeFormat::ND, float, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, float>>(v12, v7);
// CHECK-NEXT:  AscendC::GlobalTensor<float> v14 = v1.GetTensorC<c0_i1>(c0_i8, c0_i1);
// CHECK-NEXT:  v1.End();
// CHECK-NEXT:  AscendC::TPipe v15;
// CHECK-NEXT:  using namespace AscendC;
// CHECK-NEXT:  REGIST_MATMUL_OBJ(&v15, GetSysWorkSpacePtr(), v1);
// CHECK-NEXT:  return;
// CHECK-NEXT:}
func.func @emit_matmul(%arg0: !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, %arg1: !ascendc.cube_tiling, %arg2: !ascendc.pipe, %arg3: !ascendc.global_tensor<*xf32>, %arg4: i8, %arg5: !ascendc.local_tensor<*xf32>, %arg6: i32, %arg7: ui32, %arg8: memref<1024xui8, 22>, %arg9: ui8) {
  %c0_i8 = arith.constant 0 : i8
  %false = arith.constant false
  %true = arith.constant true
  ascendc.matmul.init %arg0, %arg1 : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, !ascendc.cube_tiling
  ascendc.matmul.set_tensor_a %arg0, %arg3, %arg4 : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, !ascendc.global_tensor<*xf32>, i8
  ascendc.matmul.set_tensor_b %arg0, %arg3, %arg4 : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, !ascendc.global_tensor<*xf32>, i8
  ascendc.matmul.set_hf32 %arg0, %false, %arg6 : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, i1, i32
  ascendc.matmul.set_tail %arg0, %arg6, %arg6, %arg6 : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, i32, i32, i32
  ascendc.matmul.set_batch_num %arg0, %arg6, %arg6 : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, i32, i32
  ascendc.matmul.set_workspace %arg0, %arg3 : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, !ascendc.global_tensor<*xf32>
  ascendc.matmul.set_workspace %arg0, %arg8, %arg6 : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, memref<1024xui8, 22>, i32
  ascendc.matmul.wait_get_tensor_c %arg0 : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>
  ascendc.matmul.async_get_tensor_c %arg0, %arg5 : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, !ascendc.local_tensor<*xf32>
  ascendc.matmul.iterate_n_batch %arg0, %arg6, %arg6, %arg6, %false, %arg6, %arg6, %arg6, %false, %false : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, i32, i32, i32, i1, i32, i32, i32, i1, i1
  ascendc.matmul.set_bias %arg0, %arg3 : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, !ascendc.global_tensor<*xf32>
  ascendc.matmul.disable_bias %arg0 : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>
  %0 = ascendc.matmul.iterate %arg0, %false, %true : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, i1, i1, , i1
  ascendc.matmul.get_tensor_c %arg0, %arg5, %c0_i8, %true, %true : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, !ascendc.local_tensor<*xf32>, i8, i1, i1
  ascendc.matmul.iterate_all %arg0, %arg3, %arg4, %false, %true, %false, %false {operandSegmentSizes = array<i32: 1, 1, 1, 1, 1, 1, 1>} : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, !ascendc.global_tensor<*xf32>, i8, i1, i1, i1, i1
  ascendc.matmul.wait_iterate_all %arg0 : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>
  ascendc.matmul.iterate_batch %arg0, %arg3, %arg7, %arg7, %false, %arg7, %arg7, %arg7, %false, %arg4, %false, %true {operandSegmentSizes = array<i32: 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1>} : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, !ascendc.global_tensor<*xf32>, ui32, ui32, i1, ui32, ui32, ui32, i1, i8, i1, i1
  ascendc.matmul.wait_iterate_batch %arg0 : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>
  %9 = ascendc.construct !ascendc.matmul_config()
  emitasc.set_member %9 "doNorm", %false : !ascendc.matmul_config, i1
  emitasc.set_member %9 "iterateMode", %arg9 : !ascendc.matmul_config, ui8
  emitasc.set_member %9 "singleCoreMN", %arg7 : !ascendc.matmul_config, ui32
  %10 = ascendc.get_matmul_api_tiling %9, %arg6 {matmulType = !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, veccalc, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>} : !ascendc.matmul_config, i32
  %11 = ascendc.matmul.get_tensor_c_return %arg0, %c0_i8, %false, %false : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, i8, i1, i1, !ascendc.global_tensor<*xf32>
  ascendc.matmul.end %arg0 : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>
  %12 = ascendc.pipe
  ascendc.regist_matmul_obj %12, %arg0 : !ascendc.pipe, !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>
  return
}

// CHECK:void emit_set_user_def_info(__gm__ half* v1) {
// CHECK-NEXT:  constexpr static MatmulConfig CFG{1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,BatchMode::NONE,1,1,1,1,1,1,1,255,1,0,0,0,IterateOrder::UNDEF,ScheduleType::INNER_PRODUCT,0,1,0,0,0,0,0,0,0,65536,BatchOutMode::SINGLE_BATCH};matmul::Matmul<matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, half, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, half, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, half, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, half>, CFG> v2;
// CHECK-NEXT:  v2.SetUserDefInfo(reinterpret_cast<uint64_t>(v1));
// CHECK-NEXT:  return;
// CHECK-NEXT:}
func.func @emit_set_user_def_info(%arg0: memref<?xf16, 22>) {
  %3 = ascendc.construct !ascendc.matmul<gm, 0 : i32, f16, false, 0 : i32, gm, 0 : i32, f16, false, 0 : i32, gm, 0 : i32, f16, false, 0 : i32, gm, 0 : i32, f16, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>()
  ascendc.matmul.set_user_def_info %3, %arg0 : !ascendc.matmul<gm, 0 : i32, f16, false, 0 : i32, gm, 0 : i32, f16, false, 0 : i32, gm, 0 : i32, f16, false, 0 : i32, gm, 0 : i32, f16, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, memref<?xf16, 22>
  return
}

// CHECK:void emit_set_self_define_data(__gm__ half* v1) {
// CHECK-NEXT:  constexpr static MatmulConfig CFG{1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,BatchMode::NONE,1,1,1,1,1,1,1,255,1,0,0,0,IterateOrder::UNDEF,ScheduleType::INNER_PRODUCT,0,1,0,0,0,0,0,0,0,65536,BatchOutMode::SINGLE_BATCH};matmul::Matmul<matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, half, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, half, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, half, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, half>, CFG> v2;
// CHECK-NEXT:  v2.SetSelfDefineData(reinterpret_cast<uint64_t>(v1));
// CHECK-NEXT:  return;
// CHECK-NEXT:}
func.func @emit_set_self_define_data(%arg0: memref<?xf16, 22>) {
  %3 = ascendc.construct !ascendc.matmul<gm, 0 : i32, f16, false, 0 : i32, gm, 0 : i32, f16, false, 0 : i32, gm, 0 : i32, f16, false, 0 : i32, gm, 0 : i32, f16, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>()
  ascendc.matmul.set_self_define_data %3, %arg0 : !ascendc.matmul<gm, 0 : i32, f16, false, 0 : i32, gm, 0 : i32, f16, false, 0 : i32, gm, 0 : i32, f16, false, 0 : i32, gm, 0 : i32, f16, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, memref<?xf16, 22>
  return
}

// CHECK:     #define ASCENDC_CUBE_ONLY
// CHECK:void emit_set_sparse_index(AscendC::GlobalTensor<uint8_t> v1) {
// CHECK-NEXT:  constexpr static MatmulConfig CFG{1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,BatchMode::NONE,1,1,1,1,1,1,1,255,1,0,0,0,IterateOrder::UNDEF,ScheduleType::INNER_PRODUCT,0,1,0,0,0,0,0,0,0,65536,BatchOutMode::SINGLE_BATCH};matmul::Matmul<matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, half, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, half, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, half, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, half>, CFG> v2;
// CHECK-NEXT:  v2.SetSparseIndex(v1);
// CHECK-NEXT:  return;
// CHECK-NEXT:}
emitc.verbatim "#define ASCENDC_CUBE_ONLY"
func.func @emit_set_sparse_index(%arg0: !ascendc.global_tensor<*xui8>) {
  %3 = ascendc.construct !ascendc.matmul<gm, 0 : i32, f16, false, 0 : i32, gm, 0 : i32, f16, false, 0 : i32, gm, 0 : i32, f16, false, 0 : i32, gm, 0 : i32, f16, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>()
  ascendc.matmul.set_sparse_index %3, %arg0 : !ascendc.matmul<gm, 0 : i32, f16, false, 0 : i32, gm, 0 : i32, f16, false, 0 : i32, gm, 0 : i32, f16, false, 0 : i32, gm, 0 : i32, f16, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, !ascendc.global_tensor<*xui8>
  return
}

// CHECK-LABEL:void emit_matmul_quant(constexpr static MatmulConfig CFG{1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,BatchMode::NONE,1,1,1,1,1,1,1,255,1,0,0,0,IterateOrder::UNDEF,ScheduleType::INNER_PRODUCT,0,1,0,0,0,0,0,0,0,65536,BatchOutMode::SINGLE_BATCH};matmul::Matmul<matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, float, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, float, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, float, false, LayoutMode::NONE>, matmul::MatmulType<AscendC::TPosition::GM, CubeFormat::ND, float>, CFG> v1, uint64_t v2, AscendC::GlobalTensor<uint64_t> v3, int32_t v4, int32_t v5) {
// CHECK-NEXT:  v1.SetQuantScalar(v2);
// CHECK-NEXT:  v1.SetQuantVector(v3);
// CHECK-NEXT:  v1.SetOrgShape(v4, v4, v5);
// CHECK-NEXT:  v1.SetOrgShape(v4, v4, v5, v5, v5);
// CHECK-NEXT:  v1.SetSingleShape(v5, v5, v5);
// CHECK-NEXT:  return;
// CHECK-NEXT:}
func.func @emit_matmul_quant(%arg0: !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, %arg1: ui64, %arg2: !ascendc.global_tensor<ui64>, %arg3: i32, %arg4: i32) {
  ascendc.matmul.set_quant_scalar %arg0, %arg1 : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, ui64
  ascendc.matmul.set_quant_vector %arg0, %arg2 : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, !ascendc.global_tensor<ui64>
  ascendc.matmul.set_org_shape %arg0, %arg3, %arg3, %arg4 {operandSegmentSizes = array<i32: 1, 1, 1, 1, 0, 0>} : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, i32, i32, i32
  ascendc.matmul.set_org_shape %arg0, %arg3, %arg3, %arg4, %arg4, %arg4 {operandSegmentSizes = array<i32: 1, 1, 1, 1, 1, 1>} : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, i32, i32, i32, i32, i32
  ascendc.matmul.set_single_shape %arg0, %arg4, %arg4, %arg4 : !ascendc.matmul<gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, false, 0 : i32, gm, 0 : i32, f32, <do_norm = true, do_basic_block = false, do_multi_data_load = false, basic_m = 0 : i32, basic_n = 0 : i32, basic_k = 0 : i32, intrinsics_check = false, is_n_batch = false, en_vec_nd2nz = false, do_special_basic_block = false, do_mte2_preload = 0 : i32, single_core_m = 0 : i32, single_core_n = 0 : i32, single_core_k = 0 : i32, step_m = 0 : i32, step_n = 0 : i32, base_mn = 0 : i32, single_core_mn = 0 : i32, en_unit_flag = true, is_per_tensor = false, has_anti_quant_offset = false, do_ib_share_norm = false, do_special_mdl = false, enable_init = true, batch_mode = 0 : i32, enable_end = true, enable_get_tensor_c = true, enable_set_org_shape = true, enable_set_bias = true, enable_set_tail = true, enable_quant_vector = true, enable_set_define_data = true, iterate_mode = 255 : i32, enable_reuse = true, enable_ub_reuse = false, enable_l1_cache_ub = false, intra_block_part_sum = false, iterate_order = 2 : i32, schedule_type = 0 : i32, enable_double_cache = false, is_bias_batch = true, enable_static_pad_zeros = false, is_partial_output = false, enable_mix_dual_master = false, is_a2b2_shared = false, is_enable_channel_split = false, enable_kdim_reorder_load = false, is_co1_shared = false, shared_co1_buffer_size = 65536 : i32, batch_out_mode = 0 : i32>>, i32, i32, i32
  return
}
